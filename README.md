# Multi-Objective Reinforcement Learning (MORL) - HalfCheetah

Bu proje, HalfCheetah ortamÄ±nda Ã‡ok AmaÃ§lÄ± PekiÅŸtirmeli Ã–ÄŸrenme (Multi-Objective Reinforcement Learning, MORL) algoritmalarÄ±nÄ± implement eden kapsamlÄ± bir framework'tÃ¼r. PPO (Proximal Policy Optimization) ve GRPO (Gradient Projection-based Optimization) algoritmalarÄ± kullanarak Ã§oklu objektif optimizasyonu gerÃ§ekleÅŸtirir.

## ğŸš€ Ã–zellikler

- **HalfCheetah MORL OrtamÄ±**: Ã–zelleÅŸtirilmiÅŸ 3 amaÃ§lÄ± (hÄ±z, enerji verimliliÄŸi, hareket yumuÅŸaklÄ±ÄŸÄ±) ortam
- **PPO + GRPO AlgoritmasÄ±**: Grup tabanlÄ± gradient projection ile geliÅŸtirilmiÅŸ PPO
- **Tercih Ã–rnekleme**: Dirichlet daÄŸÄ±lÄ±mÄ± ve kÃ¶ÅŸe noktalarÄ± ile tercih vektÃ¶rÃ¼ Ã¼retimi
- **KapsamlÄ± Metrikler**: 
  - Hypervolume (Monte Carlo & Exact)
  - IGD (Inverted Generational Distance)
  - IGD+ metrikleri
- **GÃ¶rselleÅŸtirme**: UMAP/t-SNE ile embedding manifold analizi
- **Pareto Front Analizi**: Ã‡ok amaÃ§lÄ± optimizasyon sonuÃ§larÄ±nÄ±n analizi
- **Toplu Deneyim**: Ã‡oklu seed ve varyant ile otomatik deneyim yÃ¼rÃ¼tme

## ğŸ“‹ Gereksinimler

### Temel KÃ¼tÃ¼phaneler
```
gymnasium
mujoco
pymoo
numpy
pandas
matplotlib
seaborn
scikit-learn
umap-learn
python-ternary
```

## ğŸ›  Kurulum

### 1. Gerekli kÃ¼tÃ¼phaneleri yÃ¼kleyin:
```bash
pip install -r requirements.txt
```

### 2. Depoyu klonlayÄ±n:
```bash
git clone https://github.com/AykutN/policy_collapse.git
cd policy_collapse
```

## ğŸ“– KullanÄ±m

### Temel EÄŸitim

Tek bir deneyim Ã§alÄ±ÅŸtÄ±rmak iÃ§in:

```bash
python training_morl_example.py --max_episodes 5000 --update_timestep 4000
```

### GeliÅŸmiÅŸ SeÃ§enekler

```bash
python training_morl_example.py \
    --max_episodes 10000 \
    --update_timestep 4000 \
    --K_epochs 20 \
    --entropy_coef 0.01 \
    --exact_hv \
    --manifold umap \
    --embed_interval 50 \
    --summary_table
```

### Ã‡oklu Deneyim (FarklÄ± Seed'ler)

```bash
python run_many.py \
    --seeds 0 1 2 3 4 \
    --episodes 5000 \
    --exact_hv \
    --manifold umap \
    --variants grpo no-grpo
```

### Google Colab KullanÄ±mÄ±

Google Colab'da Ã§alÄ±ÅŸtÄ±rmak iÃ§in `colab_morl_halfcheetah.ipynb` notebook'unu kullanabilirsiniz. Bu notebook otomatik kurulum ve fallback ortam iÃ§erir.

## ğŸ“Š Analiz ve GÃ¶rselleÅŸtirme

### Temel Grafik Ã‡izimi

```bash
python grafik_cizdir.py --run_dir logs/run_XXXXXX
```

### GeliÅŸmiÅŸ Analiz

```bash
python advanced_analysis.py --all --log_dir logs
```

### Embedding GÃ¶rselleÅŸtirme

```bash
python embed_visualize.py --run_dir logs/run_XXXXXX
```

## ğŸ“ Proje YapÄ±sÄ±

```
â”œâ”€â”€ training_morl_example.py    # Ana eÄŸitim scripti
â”œâ”€â”€ morl_env_halfcheetah.py     # HalfCheetah MORL ortam wrapper'Ä±
â”œâ”€â”€ utils_prefs.py              # Tercih vektÃ¶rÃ¼ yardÄ±mcÄ± fonksiyonlarÄ±
â”œâ”€â”€ run_many.py                 # Ã‡oklu deneyim yÃ¼rÃ¼tÃ¼cÃ¼
â”œâ”€â”€ grafik_cizdir.py           # Temel grafik Ã§izim araÃ§larÄ±
â”œâ”€â”€ advanced_analysis.py        # Ä°leri seviye analiz araÃ§larÄ±
â”œâ”€â”€ embed_visualize.py          # Embedding gÃ¶rselleÅŸtirme
â”œâ”€â”€ colab_morl_halfcheetah.ipynb # Google Colab notebook'u
â””â”€â”€ requirements.txt            # Gerekli kÃ¼tÃ¼phaneler
```

## ğŸ¯ MORL OrtamÄ± DetaylarÄ±

### HalfCheetah-v4 AmaÃ§larÄ±

1. **HÄ±z Objektifi**: Hedef hÄ±za ulaÅŸma/sÃ¼rdÃ¼rme
2. **Enerji VerimliliÄŸi**: Minimum enerji tÃ¼ketimi
3. **Hareket YumuÅŸaklÄ±ÄŸÄ±**: Aksiyon deÄŸiÅŸimlerini minimize etme

### Ortam KonfigÃ¼rasyonu

```python
from morl_env_halfcheetah import make_hc_morl

env = make_hc_morl(
    speed_mode="target_speed",
    target_speed=2.0,
    alpha_energy=0.1,
    beta_smooth=0.05,
    normalize=True,
    friction_rand=True,
    seed=42
)
```

## ğŸ“ˆ Metrikler ve DeÄŸerlendirme

### Hypervolume (HV)
- Monte Carlo tahmini (hÄ±zlÄ±)
- Exact hesaplama (pymoo, 3 amaÃ§ iÃ§in)

### IGD ve IGD+ Metrikleri
- Referans Pareto front ile karÅŸÄ±laÅŸtÄ±rma
- Convergence ve diversity Ã¶lÃ§Ã¼mÃ¼

### Embedding Analizi
- UMAP/t-SNE ile action-preference space gÃ¶rselleÅŸtirme
- Policy manifold analizi

## ğŸ”§ Parametre AyarlarÄ±

### Ana EÄŸitim Parametreleri

| Parametre | VarsayÄ±lan | AÃ§Ä±klama |
|-----------|------------|----------|
| `--max_episodes` | 50000 | Maksimum episode sayÄ±sÄ± |
| `--update_timestep` | 4000 | GÃ¼ncelleme aralÄ±ÄŸÄ± |
| `--K_epochs` | 20 | PPO epoch sayÄ±sÄ± |
| `--entropy_coef` | 0.01 | Entropy katsayÄ±sÄ± |
| `--exact_hv` | False | Exact hypervolume hesaplama |
| `--manifold` | none | Embedding tipi (umap/tsne/none) |

### GRPO Parametreleri

| Parametre | VarsayÄ±lan | AÃ§Ä±klama |
|-----------|------------|----------|
| `--no_grpo` | False | GRPO'yu devre dÄ±ÅŸÄ± bÄ±rak |
| `grpo_group_mode` | knn | GruplandÄ±rma modu |
| `grpo_knn_delta` | 0.15 | KNN delta threshold |

## ğŸ“Š Ã‡Ä±ktÄ± DosyalarÄ±

### EÄŸitim Ã‡Ä±ktÄ±larÄ±
- `logs/run_XXXXXX/metrics.csv` - EÄŸitim metrikleri
- `logs/run_XXXXXX/summary.csv` - Ã–zet istatistikler
- `logs/run_XXXXXX/final_front.npy` - Son Pareto front

### Analiz Ã‡Ä±ktÄ±larÄ±
- `logs/run_XXXXXX/analysis/` - Grafik ve analiz dosyalarÄ±
- `logs/run_XXXXXX/embeddings/` - UMAP/t-SNE embeddings

### Toplu Analiz
- `logs/aggregate_summary.csv` - TÃ¼m run'larÄ±n Ã¶zeti
- `logs/aggregate_summary_stats.csv` - Ä°statistiksel Ã¶zetler

## ğŸ¤ KatkÄ±da Bulunma

1. Fork yapÄ±n
2. Feature branch oluÅŸturun (`git checkout -b feature/amazing-feature`)
3. DeÄŸiÅŸikliklerinizi commit edin (`git commit -m 'Add amazing feature'`)
4. Branch'inizi push edin (`git push origin feature/amazing-feature`)
5. Pull Request aÃ§Ä±n

## ğŸ“„ Lisans

Bu proje MIT lisansÄ± altÄ±nda lisanslanmÄ±ÅŸtÄ±r.

## ğŸ“ Ä°letiÅŸim

Aykut N. - [@AykutN](https://github.com/AykutN)

Proje Linki: [https://github.com/AykutN/policy_collapse](https://github.com/AykutN/policy_collapse)

## ğŸ™ TeÅŸekkÃ¼rler

- [Gymnasium](https://gymnasium.farama.org/) - RL ortamlarÄ±
- [MuJoCo](https://mujoco.org/) - Fizik simÃ¼lasyonu
- [PyMOO](https://pymoo.org/) - Multi-objective optimization
- [UMAP](https://umap-learn.readthedocs.io/) - Dimensionality reduction